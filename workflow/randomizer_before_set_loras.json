{
    "1": {
        "inputs": {
            "ckpt_name": "abyssorangemix2NSFW_abyssorangemix2Nsfw.safetensors"
        },
        "class_type": "CheckpointLoaderSimple",
        "_meta": {
            "title": "Load Checkpoint"
        }
    },
    "2": {
        "inputs": {
            "stop_at_clip_layer": -2,
            "clip": [
                "1",
                1
            ]
        },
        "class_type": "CLIPSetLastLayer",
        "_meta": {
            "title": "CLIP Set Last Layer"
        }
    },
    "3": {
        "inputs": {
            "text": "a robot in year 2077, cyberpunk style, cowboy shot",
            "clip": [
                "8",
                1
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "Positive"
        }
    },
    "4": {
        "inputs": {
            "text": "embedding: easyNegative",
            "clip": [
                "8",
                1
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "Negative"
        }
    },
    "5": {
        "inputs": {
            "lora_name": "2b_nier_automata.safetensors",
            "strength_model": 1,
            "strength_clip": 1,
            "model": [
                "1",
                0
            ],
            "clip": [
                "2",
                0
            ]
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora1"
        }
    },
    "6": {
        "inputs": {
            "lora_name": "2b_nier_automata.safetensors",
            "strength_model": 1,
            "strength_clip": 1,
            "model": [
                "5",
                0
            ],
            "clip": [
                "5",
                1
            ]
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora2"
        }
    },
    "7": {
        "inputs": {
            "lora_name": "2b_nier_automata.safetensors",
            "strength_model": 1,
            "strength_clip": 1,
            "model": [
                "6",
                0
            ],
            "clip": [
                "6",
                1
            ]
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora3"
        }
    },
    "8": {
        "inputs": {
            "lora_name": "2b_nier_automata.safetensors",
            "strength_model": 1,
            "strength_clip": 1,
            "model": [
                "7",
                0
            ],
            "clip": [
                "7",
                1
            ]
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora4"
        }
    },
    "9": {
        "inputs": {
            "seed": 0,
            "steps": 20,
            "cfg": 8,
            "sampler_name": "dpmpp_2m",
            "scheduler": "karras",
            "denoise": 1,
            "model": [
                "8",
                0
            ],
            "positive": [
                "3",
                0
            ],
            "negative": [
                "4",
                0
            ],
            "latent_image": [
                "10",
                0
            ]
        },
        "class_type": "KSampler",
        "_meta": {
            "title": "KSampler"
        }
    },
    "10": {
        "inputs": {
            "width": 512,
            "height": 512,
            "batch_size": 1
        },
        "class_type": "EmptyLatentImage",
        "_meta": {
            "title": "Empty Latent Image"
        }
    },
    "11": {
        "inputs": {
            "samples": [
                "9",
                0
            ],
            "vae": [
                "1",
                2
            ]
        },
        "class_type": "VAEDecode",
        "_meta": {
            "title": "VAE Decode"
        }
    },
    "12": {
        "inputs": {
            "filename_prefix": "ComfyUI",
            "images": [
                "11",
                0
            ]
        },
        "class_type": "SaveImage",
        "_meta": {
            "title": "Save Image"
        }
    },
    "13": {
        "inputs": {
            "upscale_model": [
                "14",
                0
            ],
            "image": [
                "11",
                0
            ]
        },
        "class_type": "ImageUpscaleWithModel",
        "_meta": {
            "title": "Upscale Image (using Model)"
        }
    },
    "14": {
        "inputs": {
            "model_name": "4x-AnimeSharp.pth"
        },
        "class_type": "UpscaleModelLoader",
        "_meta": {
            "title": "Load Upscale Model"
        }
    },
    "15": {
        "inputs": {
            "pixels": [
                "17",
                0
            ],
            "vae": [
                "1",
                2
            ]
        },
        "class_type": "VAEEncode",
        "_meta": {
            "title": "VAE Encode"
        }
    },
    "16": {
        "inputs": {
            "seed": 0,
            "steps": 10,
            "cfg": 8,
            "sampler_name": "dpmpp_2m",
            "scheduler": "karras",
            "denoise": 0.4,
            "model": [
                "8",
                0
            ],
            "positive": [
                "3",
                0
            ],
            "negative": [
                "4",
                0
            ],
            "latent_image": [
                "15",
                0
            ]
        },
        "class_type": "KSampler",
        "_meta": {
            "title": "KS_up"
        }
    },
    "17": {
        "inputs": {
            "upscale_method": "nearest-exact",
            "width": 512,
            "height": 512,
            "crop": "disabled",
            "image": [
                "13",
                0
            ]
        },
        "class_type": "ImageScale",
        "_meta": {
            "title": "Up_res"
        }
    },
    "18": {
        "inputs": {
            "samples": [
                "16",
                0
            ],
            "vae": [
                "1",
                2
            ]
        },
        "class_type": "VAEDecode",
        "_meta": {
            "title": "VAE Decode_scaled"
        }
    },
    "20": {
        "inputs": {
            "vae_name": "kl-f8-anime2.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
            "title": "Load VAE"
        }
    },
    "21": {
        "inputs": {
            "lora_name": "2b_nier_automata.safetensors",
            "strength_model": 1,
            "strength_clip": 1
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora5"
        }
    },
    "22": {
        "inputs": {
            "lora_name": "2b_nier_automata.safetensors",
            "strength_model": 1,
            "strength_clip": 1
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora6"
        }
    },
    "23": {
        "inputs": {
            "lora_name": "2b_nier_automata.safetensors",
            "strength_model": 1,
            "strength_clip": 1
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora7"
        }
    },
    "24": {
        "inputs": {
            "text_input": "",
            "task": "more_detailed_caption",
            "fill_mask": true,
            "keep_model_loaded": false,
            "max_new_tokens": 1024,
            "num_beams": 3,
            "do_sample": true,
            "output_mask_select": "",
            "seed": 1,
            "image": [
                "28",
                0
            ],
            "florence2_model": [
                "26",
                0
            ]
        },
        "class_type": "Florence2Run",
        "_meta": {
            "title": "Florence2Run"
        }
    },
    "26": {
        "inputs": {
            "model": "thwri/CogFlorence-2.2-Large",
            "precision": "fp16",
            "attention": "sdpa"
        },
        "class_type": "DownloadAndLoadFlorence2Model",
        "_meta": {
            "title": "DownloadAndLoadFlorence2Model"
        }
    },
    "27": {
        "inputs": {
            "anything": [
                "24",
                2
            ]
        },
        "class_type": "easy showAnything",
        "_meta": {
            "title": "Show Any"
        }
    },
    "28": {
        "inputs": {
            "image": "3JTVB0BM0GVFKKD80MA6FVNDS0.jpeg",
            "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
            "title": "Load Image"
        }
    }
}