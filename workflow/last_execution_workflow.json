{
    "1": {
        "inputs": {
            "ckpt_name": "dreamshaper_8.safetensors"
        },
        "class_type": "CheckpointLoaderSimple",
        "_meta": {
            "title": "Load Checkpoint"
        }
    },
    "2": {
        "inputs": {
            "stop_at_clip_layer": -2,
            "clip": [
                "1",
                1
            ]
        },
        "class_type": "CLIPSetLastLayer",
        "_meta": {
            "title": "CLIP Set Last Layer"
        }
    },
    "3": {
        "inputs": {
            "text": "1mechanical girl,ultra realistic details, portrait, global illumination, shadows, octane render, 8k, ultra sharp,intricate, ornaments detailed, cold colors, metal, egypician detail, highly intricate details, realistic light, trending on cgsociety, glowing eyes, facing camera, neon details, machanical limbs,blood vessels connected to tubes,mechanical vertebra attaching to back,mechanical cervial attaching to neck,sitting,wires and cables connecting to head, pxint, fashion photography, glamorous, stylish attire, captivating pose, dynamic composition, high-fashion aesthetic, professional studio lighting, expert styling, showcasing trend, conveying elegance, conveying attitude, evoking emotion, creating visual impact, editorial storytelling, artistic interpretation, fashion-forward visual, masterpiece, best quality, ultra-detailed",
            "clip": [
                "5",
                1
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "Positive"
        }
    },
    "4": {
        "inputs": {
            "text": "NG_DeepNegative_V1_75T, badhandv4, easynegative, an14, bad anatomy, comics, cropped, cross-eyed, worst quality, low quality, painting, 3D render, drawing, crayon, sketch, graphite, impressionist, cartoon, anime, noisy, blurry, soft, deformed, ugly, lowres, low details, JPEG artifacts, airbrushed, semi-realistic, CGI, render, Blender, digital art, manga, amateur, mutilated, distorted, bad quality, low quality, low resolution",
            "clip": [
                "5",
                1
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "Negative"
        }
    },
    "5": {
        "inputs": {
            "lora_name": "AbstractMalePortraits_v2R_60_R-128.safetensors",
            "strength_model": 0.9,
            "strength_clip": 1,
            "model": [
                "1",
                0
            ],
            "clip": [
                "2",
                0
            ]
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora1"
        }
    },
    "6": {
        "inputs": {
            "lora_name": "bichu-v0612.safetensors",
            "strength_model": 1.0,
            "strength_clip": 1
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora2"
        }
    },
    "7": {
        "inputs": {
            "lora_name": "AMechaSSS.safetensors",
            "strength_model": 1.3,
            "strength_clip": 1
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora3"
        }
    },
    "8": {
        "inputs": {
            "lora_name": "animeoutlineV4_16.safetensors",
            "strength_model": 0.9,
            "strength_clip": 1
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora4"
        }
    },
    "9": {
        "inputs": {
            "seed": 505605,
            "steps": 20,
            "cfg": 7,
            "sampler_name": "dpmpp_2m",
            "scheduler": "karras",
            "denoise": 1,
            "model": [
                "5",
                0
            ],
            "positive": [
                "3",
                0
            ],
            "negative": [
                "4",
                0
            ],
            "latent_image": [
                "10",
                0
            ]
        },
        "class_type": "KSampler",
        "_meta": {
            "title": "KSampler"
        }
    },
    "10": {
        "inputs": {
            "width": 512,
            "height": 768,
            "batch_size": 1
        },
        "class_type": "EmptyLatentImage",
        "_meta": {
            "title": "Empty Latent Image"
        }
    },
    "11": {
        "inputs": {
            "samples": [
                "9",
                0
            ],
            "vae": [
                "1",
                2
            ]
        },
        "class_type": "VAEDecode",
        "_meta": {
            "title": "VAE Decode"
        }
    },
    "12": {
        "inputs": {
            "filename_prefix": "dreamshaper_8-Photography - Fashion-Abstr",
            "images": [
                "18",
                0
            ]
        },
        "class_type": "SaveImage",
        "_meta": {
            "title": "Save Image"
        }
    },
    "13": {
        "inputs": {
            "upscale_model": [
                "14",
                0
            ],
            "image": [
                "11",
                0
            ]
        },
        "class_type": "ImageUpscaleWithModel",
        "_meta": {
            "title": "Upscale Image (using Model)"
        }
    },
    "14": {
        "inputs": {
            "model_name": "4x-AnimeSharp.pth"
        },
        "class_type": "UpscaleModelLoader",
        "_meta": {
            "title": "Load Upscale Model"
        }
    },
    "15": {
        "inputs": {
            "pixels": [
                "17",
                0
            ],
            "vae": [
                "1",
                2
            ]
        },
        "class_type": "VAEEncode",
        "_meta": {
            "title": "VAE Encode"
        }
    },
    "16": {
        "inputs": {
            "seed": 0,
            "steps": 10,
            "cfg": 8,
            "sampler_name": "dpmpp_2m",
            "scheduler": "karras",
            "denoise": 0.4,
            "model": [
                "5",
                0
            ],
            "positive": [
                "3",
                0
            ],
            "negative": [
                "4",
                0
            ],
            "latent_image": [
                "15",
                0
            ]
        },
        "class_type": "KSampler",
        "_meta": {
            "title": "KS_up"
        }
    },
    "17": {
        "inputs": {
            "upscale_method": "nearest-exact",
            "width": 1024,
            "height": 1536,
            "crop": "disabled",
            "image": [
                "13",
                0
            ]
        },
        "class_type": "ImageScale",
        "_meta": {
            "title": "Up_res"
        }
    },
    "18": {
        "inputs": {
            "samples": [
                "16",
                0
            ],
            "vae": [
                "1",
                2
            ]
        },
        "class_type": "VAEDecode",
        "_meta": {
            "title": "VAE Decode_scaled"
        }
    },
    "20": {
        "inputs": {
            "vae_name": "kl-f8-anime2.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
            "title": "Load VAE"
        }
    },
    "21": {
        "inputs": {
            "lora_name": "AMechaSSS.safetensors",
            "strength_model": 1.4,
            "strength_clip": 1
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora5"
        }
    },
    "22": {
        "inputs": {
            "lora_name": "2b_nier_automata.safetensors",
            "strength_model": 1,
            "strength_clip": 1
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora6"
        }
    },
    "23": {
        "inputs": {
            "lora_name": "2b_nier_automata.safetensors",
            "strength_model": 1,
            "strength_clip": 1
        },
        "class_type": "LoraLoader",
        "_meta": {
            "title": "Lora7"
        }
    },
    "24": {
        "inputs": {
            "text_input": "",
            "task": "more_detailed_caption",
            "fill_mask": true,
            "keep_model_loaded": false,
            "max_new_tokens": 1024,
            "num_beams": 3,
            "do_sample": true,
            "output_mask_select": "",
            "seed": 1,
            "image": [
                "28",
                0
            ],
            "florence2_model": [
                "26",
                0
            ]
        },
        "class_type": "Florence2Run",
        "_meta": {
            "title": "Florence2Run"
        }
    },
    "26": {
        "inputs": {
            "model": "thwri/CogFlorence-2.2-Large",
            "precision": "fp16",
            "attention": "sdpa"
        },
        "class_type": "DownloadAndLoadFlorence2Model",
        "_meta": {
            "title": "DownloadAndLoadFlorence2Model"
        }
    },
    "27": {
        "inputs": {
            "anything": [
                "24",
                2
            ]
        },
        "class_type": "easy showAnything",
        "_meta": {
            "title": "Show Any"
        }
    },
    "28": {
        "inputs": {
            "image": "3JTVB0BM0GVFKKD80MA6FVNDS0.jpeg",
            "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
            "title": "Load Image"
        }
    }
}
// Datetime stamp: 2025-01-17T16:06:44.547708
